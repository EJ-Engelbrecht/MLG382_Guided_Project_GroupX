{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\Karl\\AppData\\Local\\Temp\\ipykernel_31612\\2221578146.py:12: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df = pd.read_csv('..\\data\\Student_performance_data.csv', delimiter=\",\")\n",
      "C:\\Users\\Karl\\AppData\\Local\\Temp\\ipykernel_31612\\2221578146.py:12: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df = pd.read_csv('..\\data\\Student_performance_data.csv', delimiter=\",\")\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     26\u001b[39m pipeline = Pipeline(steps=[\n\u001b[32m     27\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mclf\u001b[39m\u001b[33m'\u001b[39m, XGBClassifier(eval_metric=\u001b[33m'\u001b[39m\u001b[33mmlogloss\u001b[39m\u001b[33m'\u001b[39m, random_state=\u001b[32m8\u001b[39m))\n\u001b[32m     28\u001b[39m ])\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m#pipe\u001b[39;00m\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m#Step 5: Set up hyperparameter tuning\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mskopt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BayesSearchCV\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mskopt\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspace\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Real,Categorical, Integer\n\u001b[32m     35\u001b[39m search_space = {\n\u001b[32m     36\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclf__max_depth\u001b[39m\u001b[33m'\u001b[39m : Integer(\u001b[32m2\u001b[39m,\u001b[32m8\u001b[39m),\n\u001b[32m     37\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclf__learning_rate\u001b[39m\u001b[33m'\u001b[39m : Real(\u001b[32m0.001\u001b[39m, \u001b[32m1.0\u001b[39m, prior=\u001b[33m'\u001b[39m\u001b[33mlog-uniform\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclf__gamma\u001b[39m\u001b[33m'\u001b[39m : Real(\u001b[32m0.0\u001b[39m, \u001b[32m10.0\u001b[39m)\n\u001b[32m     45\u001b[39m }\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'skopt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "#Step 1: Import CSVs\n",
    "df = pd.read_csv('..\\data\\Student_performance_data.csv', delimiter=\",\")\n",
    "\n",
    "#Step 2: Separate features and target\n",
    "X = df.drop(columns=[\"StudentID\", \"GradeClass\", \"GPA\"])\n",
    "y = df['GradeClass']\n",
    "\n",
    "#Step 3: Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50, stratify=df['GradeClass'])\n",
    "\n",
    "#Step 4: Build a pipeline of training\n",
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "\n",
    "#Step 4: Train XGBoost Model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('clf', XGBClassifier(eval_metric='mlogloss', random_state=8))\n",
    "])\n",
    "#pipe\n",
    "\n",
    "#Step 5: Set up hyperparameter tuning\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real,Categorical, Integer\n",
    "\n",
    "search_space = {\n",
    "    'clf__max_depth' : Integer(2,8),\n",
    "    'clf__learning_rate' : Real(0.001, 1.0, prior='log-uniform'),\n",
    "    'clf__subsample' : Real(0.5, 1.0),\n",
    "    'clf__colsample_bytree' : Real(0.5, 1.0),\n",
    "    'clf__colsample_bylevel' : Real(0.5, 1.0),\n",
    "    'clf__colsample_bynode' : Real(0.5, 1.0),\n",
    "    'clf__reg_alpha' : Real(0.0, 10.0),\n",
    "    'clf__reg_lambda' : Real(0.0, 10.0),\n",
    "    'clf__gamma' : Real(0.0, 10.0)\n",
    "}\n",
    "\n",
    "#Step 6: Training the XGBoost model\n",
    "opt = BayesSearchCV(pipeline, search_space, cv=3, n_iter=10, scoring='accuracy', random_state=8)\n",
    "#Can change cv and n_iter to higher values\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "#Step 7: Evaluate and make predictions\n",
    "\n",
    "opt.best_estimator_\n",
    "opt.best_score_\n",
    "opt.score(X_test, y_test)\n",
    "opt.predict(X_test)\n",
    "opt.predict_proba(X_test)\n",
    "\n",
    "predictions = opt.predict(X_test)\n",
    "\n",
    "#Grade mapping\n",
    "grade_map = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'F'}\n",
    "y_test_letters = pd.Series(y_test).map(grade_map)\n",
    "y_pred_letters = pd.Series(predictions).map(grade_map)\n",
    "label_names = [grade_map[i] for i in sorted(grade_map)]\n",
    "\n",
    "#Step 8: Evaluation\n",
    "accuracy = accuracy_score(y_test_letters, y_pred_letters)\n",
    "print(\"XGBoost Accuracy:\", round(accuracy, 4))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_letters, y_pred_letters, target_names=label_names, zero_division=0))\n",
    "\n",
    "#Step 9: Evaulate feature importance\n",
    "opt.best_estimator_.steps\n",
    "\n",
    "from xgboost import plot_importance\n",
    "\n",
    "xgboost_model = opt.best_estimator_.named_steps['clf']\n",
    "plot_importance(xgboost_model)\n",
    "plt.show()\n",
    "\n",
    "# Step 10: Confusion Matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "labels = sorted(y.unique())  # Ensures label order matches\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Step 11: Save the model as pkl file in artifacts\n",
    "\n",
    "with open(\"../artifacts/xgboost_model.pkl\", \"wb\") as file:\n",
    "   pickle.dump(opt.best_estimator_, file)\n",
    "\n",
    "#Step 12: Save predictions to CSV\n",
    "comp_df = X_test.copy()\n",
    "comp_df[\"Actual_GradeClass\"] = y_test.values\n",
    "comp_df[\"Predicted_GradeClass\"] = predictions\n",
    "\n",
    "#Step 13: Show and save the predictions table\n",
    "try:\n",
    "    from IPython.display import display\n",
    "\n",
    "    # Prepare DataFrame for display\n",
    "    comp_df = pd.DataFrame({\"Actual\": y_test.values,\"Predicted\": predictions})\n",
    "    comp_df[\"Match\"] = comp_df[\"Actual\"] == comp_df[\"Predicted\"]\n",
    "\n",
    "    def highlight_false_text(row):\n",
    "        styles = []\n",
    "        for col in row.index:\n",
    "            if col == \"Match\" and row[\"Match\"] == False:\n",
    "                styles.append(\"color: red; background-color: black\")\n",
    "            else:\n",
    "                styles.append(\"background-color: black; color: white\")\n",
    "        return styles\n",
    "\n",
    "    print(\"First 20 Predictions:\")\n",
    "    display(comp_df.head(20).style.apply(highlight_false_text, axis=1))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\n First 20 Predictions:\")\n",
    "    print(comp_df.head(20).to_string(index=False))\n",
    "\n",
    "comp_df.to_csv(\"../artifacts/xgboost_prediction.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLG382_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
